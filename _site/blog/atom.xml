<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title>Irhsad Bhat's Blog</title>
    <link href="http://irshadbhat.github.io/blog/atom.xml" rel="self"/>
    <link href="http://irshadbhat.github.io/blog"/>
    <updated>2016-06-27T19:57:28+05:30</updated>
    <id>http://irshadbhat.github.io/blog</id>
    <author>
        <name>Irshad A. Bhat</name>
        <email>bhatirshad127@gmail.com</email>
    </author>

    
        <entry>
            <title>Google Summer of Code 2016 (GSoC)</title>
            <link href="http://hankquinlan.github.io/gsoc/"/>
            <updated>2016-06-26T13:33:00+05:30</updated>
            <id>http://hankquinlan.github.io//gsoc</id>
            <content type="html">&lt;p&gt;I feel privileged to have been given the opportunity to work for &lt;a href=&quot;https://github.com/libindic&quot;&gt;Libindic organization&lt;/a&gt; under the Google Summer of Code 2016. Libindic is an open source library that supports many utilities for text processing of Indian languages. I would be contributing towards the automatic script transliteration between scheduled languages of India including English. For the project, I would be mentored by &lt;a href=&quot;https://researchweb.iiit.ac.in/~riyaz.bhat/&quot;&gt;Riyaz Ahmad Bhat&lt;/a&gt; and &lt;a href=&quot;http://thottingal.in&quot;&gt;Santhosh Thottingal&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;machine-transliteration&quot;&gt;Machine Transliteration&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Transliteration&quot;&gt;Transliteration&lt;/a&gt; simply means conversion of a text from one script to another. Machine transliteration is the computer automated process of transcribing a character or word from one language script to another. Machine transliteration can play an important role in natural language application such as information retrieval and machine translation, especially for handling proper nouns and technical terms, cross-language applications, data mining and information retrieval system.&lt;/p&gt;

&lt;h2 id=&quot;project-description&quot;&gt;Project Description&lt;/h2&gt;
&lt;p&gt;A thorough description of the project goals can be seen in the original &lt;a href=&quot;https://drive.google.com/open?id=0B3ZAq0KmDeDVd3N3TnluS2tCLWM&quot;&gt;proposal&lt;/a&gt; submitted to GSoC 2016. Here I will briefly list down our contribution towards machine transliteration module of Libindic.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Indic to Indic Script Transliteration&lt;/li&gt;
  &lt;li&gt;Indic to Roman Transliteration&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;approaches&quot;&gt;Approaches&lt;/h2&gt;

&lt;h3 id=&quot;rule-basedhttpsenwikipediaorgwikirule-basedsystem&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Rule-based_system&quot;&gt;1. Rule Based&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;A rule-based transliteration system uses character mappings defined between two scripts. There are five types of character mappings possible between two natural language scripts: &lt;em&gt;One-to-One&lt;/em&gt;, &lt;em&gt;One-to-Many&lt;/em&gt;, &lt;em&gt;Many-to-One&lt;/em&gt;, &lt;em&gt;One-to-None&lt;/em&gt; and &lt;em&gt;None-to-One&lt;/em&gt;. A simple &lt;em&gt;One-to-One&lt;/em&gt; character mapping would lead to a more accurate and easy to develop system. However, natural languages are inherently ambiguous. There are many cases of ambiguity in orthographic representation of languages world over. Distribution of different types of character mappings is not generally uniform, though. The distribution is usually skewed; unambiguous characters occur more often then their ambiguous counterparts. Nonetheless, to resolve the ambiguous mappings, heuristics are designed which take the surrounding context of an ambiguous letter into consideration.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;benefits&quot;&gt;Benefits&lt;/h4&gt;
    &lt;ol&gt;
      &lt;li&gt;Rule-based transliteration systems between Indic scripts is essentially trivial. Indic scripts have a special property that their phonemes are one-to-one aligned between their Unicode tables. It essentially means that the transliteration between any two Indic scripts can be achieved by merely using their unicode tables.&lt;/li&gt;
      &lt;li&gt;Rule-based systems do not require any kind of training data to develop the system.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;challenges&quot;&gt;Challenges&lt;/h4&gt;
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Requires domain expertise&lt;/em&gt;&lt;/strong&gt;: To develop a rule-based system between two natural language scripts a domain expert is required.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Missing phonemes in Indic scripts&lt;/em&gt;&lt;/strong&gt;: The major concern with rule-based system for Indic-to-Indic transliteration is the missing phonemes in Indic scripts. For example, in Tamil there are no characters for &lt;em&gt;d&lt;/em&gt;, &lt;em&gt;dh&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt;, &lt;em&gt;bh&lt;/em&gt; etc. &lt;em&gt;d&lt;/em&gt; is pronounced as &lt;em&gt;t&lt;/em&gt;, &lt;em&gt;dh&lt;/em&gt; as &lt;em&gt;th&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt; and &lt;em&gt;bh&lt;/em&gt; are pronounced as &lt;em&gt;p&lt;/em&gt;. Similarly, in Bengali there is no character for &lt;em&gt;v&lt;/em&gt;, it is pronounced as &lt;em&gt;b&lt;/em&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Ambiguous Character Mappings&lt;/em&gt;&lt;/strong&gt;: Another major issue with rule-based system for is ambiguous character mappings between two natural language scripts. For example, Tamil has the following ambiguous characters:&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;
  &lt;center&gt;
  &lt;table class=&quot;table-fill&quot;&gt;
  &lt;tr&gt;
  &lt;th&gt;&lt;b&gt;&amp;emsp;Character&amp;emsp;&lt;/b&gt;&lt;/th&gt; &lt;th&gt;&lt;b&gt;&amp;emsp;&amp;emsp;Mapping&amp;emsp;&amp;emsp;&lt;/b&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
  &lt;td&gt;k&lt;/td&gt; &lt;td&gt;k, kh, g, gh, h&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
  &lt;td&gt;c&lt;/td&gt; &lt;td&gt;c, ch, j, jh, s&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
  &lt;td&gt;t&lt;/td&gt; &lt;td&gt;t, th, d, dh&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
  &lt;td&gt;T&lt;/td&gt; &lt;td&gt;T, Th, D, Dh&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
  &lt;td&gt;p&lt;/td&gt; &lt;td&gt;p, ph, b, bh&lt;/td&gt;
  &lt;/tr&gt;
  &lt;/table&gt;
  &lt;/center&gt;
  &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;machine-learning-mlhttpsenwikipediaorgwikimachinelearning&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;2. Machine Learning (ML)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Arthur Samuel defined machine learning as a “Field of study that gives computers the ability to learn without being explicitly programmed”. ML is a method of teaching computers to make and improve predictions or behaviors based on some training data. In case of transliteration, the training data are the transliteration pairs between the language scripts to be transliterated.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;benefits-1&quot;&gt;Benefits&lt;/h4&gt;
    &lt;ol&gt;
      &lt;li&gt;A major benefit with transliteration system is that one is not required to be a domain expert of all the languages.&lt;/li&gt;
      &lt;li&gt;ML systems are compact, more generic and less hectic to develop than the rule-based ones.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;challenges-1&quot;&gt;Challenges&lt;/h4&gt;
    &lt;ol&gt;
      &lt;li&gt;A strong list of transliteration pairs is required to train the model. However, such lists are not readily available and are expensive to create manually.&lt;/li&gt;
      &lt;li&gt;Selection of proper ML technique, data representation for training the models are some minor challenges.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;during-community-bonding&quot;&gt;During Community Bonding&lt;/h2&gt;
&lt;p&gt;During the community bonding period I explored some of the existing tools on Indic-transliteration. Created different test cases to evaluate these existing systems, to gauge the weaknesses and strengths of these systems.&lt;/p&gt;

&lt;h2 id=&quot;progress-so-far&quot;&gt;Progress So Far&lt;/h2&gt;

&lt;h3 id=&quot;development-of-training-data-for-indic-roman-transliteration-systems&quot;&gt;Development of training data for Indic-Roman transliteration systems&lt;/h3&gt;
&lt;p&gt;Since I am using ML approach to develop Indic-to-Roman transliteration systems, I need to create the training data first. As mentioned in the proposal, I use the sentence aligned ILCI parallel corpora and Indo-wordnet synsets to extract the transliteration pairs. Initially, the parallel corpus is word-aligned using GIZA++, and the alignments are refined using the grow-diag-final-and heuristic. I extract all word pairs which occur as 1-to-1 alignments in the word-aligned corpus as potential transliteration equivalents. I will explain the transliteration pair extraction process on Hindi-Roman dataset. All the other datasets follow the same procedure.&lt;/p&gt;

&lt;h4 id=&quot;word-alignments-with-giza&quot;&gt;Word alignments with GIZA++&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Download and install GIZA++ from &lt;a href=&quot;http://giza.sourceforge.net/documentation/installation.html&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Run the following bash script to word-align the parallel text files (say &lt;strong&gt;&lt;em&gt;hin.txt&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;eng.txt&lt;/em&gt;&lt;/strong&gt;):&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hin.txt
&lt;span class=&quot;nv&quot;&gt;trg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;eng.txt
plain2snt.out &lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;
mkcls -n10 -p&lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt; -V&lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;.vcb.classes
mkcls -n10 -p&lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt; -V&lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt;.vcb.classes
snt2cooc.out &lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt;.vcb &lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;.vcb &lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;.snt&quot;&lt;/span&gt; &amp;gt; &lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;.cooc&quot;&lt;/span&gt;
GIZA++ -ml 101 -S &lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt;.vcb -T &lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;.vcb -C &lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;.snt&quot;&lt;/span&gt; -CoocurrenceFile &lt;span class=&quot;nv&quot;&gt;$src&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$trg&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;.cooc&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;The resulting word-aligned file (ending with &lt;strong&gt;&lt;em&gt;A3.final&lt;/em&gt;&lt;/strong&gt;) will look like this:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Sentence pair (1) source length 6 target length 6 alignment score : 2.28771e-11
लगातार बुखार से पीड़ित हो ?
NULL ({ }) I ({ }) suffer ({ 4 5 }) from ({ 3 }) fever ({ 2 }) continuously ({ 1 }) . ({ 6 })
# Sentence pair (2) source length 10 target length 11 alignment score : 2.70124e-12
कालाजार , मलेरिया या फिर हाई फीवर हो सकता है ।
NULL ({ }) Kalajar ({ 1 }) , ({ 2 }) Malaria ({ 3 }) or ({ 4 }) high ({ }) fiver ({ 5 6 7 }) may ({ 9 }) have ({ 10 }) happened ({ 8 }) . ({ 11 })
# Sentence pair (3) source length 8 target length 9 alignment score : 8.33816e-16
हर छह माह में करें आँखों की जाँच ।
NULL ({ 4 }) Get ({ 5 }) eyes ({ 6 }) checked ({ 7 8 }) up ({ }) every ({ 1 }) six ({ 2 }) months ({ 3 }) . ({ 9 })
# Sentence pair (4) source length 4 target length 4 alignment score : 1.89822e-07
नियमित आँखें धोना ।
NULL ({ }) Washing ({ 3 }) eyes ({ 2 }) regularly ({ 1 }) . ({ 4 })
.
.
.
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;These alignments can be further improved using the &lt;a href=&quot;http://www.statmt.org/moses/?n=FactoredTraining.AlignWords&quot;&gt;grow-diag-final-and&lt;/a&gt; heuristic. Note that the numerals in curly braces are the indices of Hindi words aligned to English words. From this alignment file the one-to-one alignments are considered as the potential transliteration equivalents. To further augment the transliteration pairs I also added word pairs from Hindi-wordnet synset mappings.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;removal-of-noisy-pairs&quot;&gt;Removal of Noisy Pairs&lt;/h4&gt;
&lt;p&gt;Obviously there will be a lot of word pairs which are not transliteration equivalents rather are translation pairs or noisy alignments. To filter out the noisy word pairs I use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Levenshtein_distance&quot;&gt;Levenshtein edit distance&lt;/a&gt; measure. In order to compute the edit distances we need a character mapping table between the two scripts. A sample mapping table between Hindi and Roman scripts is shown below:&lt;/p&gt;

&lt;p&gt;
&lt;center&gt;
&lt;table class=&quot;table-fill&quot;&gt;
&lt;tr&gt;
  &lt;th colspan=&quot;8&quot;&gt;Hindi-Roman Mapping Table&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;अ&lt;/td&gt;  &lt;td&gt;a,e&lt;/td&gt;  &lt;td&gt;ल&lt;/td&gt;  &lt;td&gt;l&lt;/td&gt;  &lt;td&gt;त&lt;/td&gt;  &lt;td&gt;t,th&lt;/td&gt;  &lt;td&gt;झ&lt;/td&gt;  &lt;td&gt;jh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ब&lt;/td&gt;  &lt;td&gt;b&lt;/td&gt;  &lt;td&gt;म&lt;/td&gt;  &lt;td&gt;m&lt;/td&gt;  &lt;td&gt;द&lt;/td&gt;  &lt;td&gt;d,dh&lt;/td&gt;  &lt;td&gt;ख&lt;/td&gt;  &lt;td&gt;kh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;च&lt;/td&gt;  &lt;td&gt;c,ch&lt;/td&gt;  &lt;td&gt;न&lt;/td&gt;  &lt;td&gt;n&lt;/td&gt;  &lt;td&gt;य&lt;/td&gt;  &lt;td&gt;y,i,e&lt;/td&gt;  &lt;td&gt;ण&lt;/td&gt;  &lt;td&gt;n&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ड&lt;/td&gt;  &lt;td&gt;d,dh&lt;/td&gt;  &lt;td&gt;ओ&lt;/td&gt;  &lt;td&gt;o,u&lt;/td&gt;  &lt;td&gt;आ&lt;/td&gt;  &lt;td&gt;a,aa&lt;/td&gt;  &lt;td&gt;औ&lt;/td&gt;  &lt;td&gt;o,u&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ए&lt;/td&gt;  &lt;td&gt;e,i,y,a&lt;/td&gt;  &lt;td&gt;प&lt;/td&gt;  &lt;td&gt;p&lt;/td&gt;  &lt;td&gt;भ&lt;/td&gt;  &lt;td&gt;bh&lt;/td&gt;  &lt;td&gt;फ&lt;/td&gt;  &lt;td&gt;ph,f&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ङ&lt;/td&gt;  &lt;td&gt;n&lt;/td&gt;  &lt;td&gt;ऋ&lt;/td&gt;  &lt;td&gt;r,ri,ru&lt;/td&gt;  &lt;td&gt;छ&lt;/td&gt;  &lt;td&gt;ch&lt;/td&gt;  &lt;td&gt;ष&lt;/td&gt;  &lt;td&gt;sh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ग&lt;/td&gt;  &lt;td&gt;g,gh&lt;/td&gt;  &lt;td&gt;र&lt;/td&gt;  &lt;td&gt;r&lt;/td&gt;  &lt;td&gt;ढ&lt;/td&gt;  &lt;td&gt;dh&lt;/td&gt;  &lt;td&gt;श&lt;/td&gt;  &lt;td&gt;sh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ह&lt;/td&gt;  &lt;td&gt;h,gh&lt;/td&gt;  &lt;td&gt;स&lt;/td&gt;  &lt;td&gt;s,c&lt;/td&gt;  &lt;td&gt;ऐ&lt;/td&gt;  &lt;td&gt;e,i,y&lt;/td&gt;  &lt;td&gt;ठ&lt;/td&gt;  &lt;td&gt;th&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;इ&lt;/td&gt;  &lt;td&gt;e,i,y&lt;/td&gt;  &lt;td&gt;ट&lt;/td&gt;  &lt;td&gt;t,th&lt;/td&gt;  &lt;td&gt;ञ&lt;/td&gt;  &lt;td&gt;n&lt;/td&gt;  &lt;td&gt;ऊ&lt;/td&gt;  &lt;td&gt;o,u&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ज&lt;/td&gt;  &lt;td&gt;j,jh,z,g&lt;/td&gt;  &lt;td&gt;उ&lt;/td&gt;  &lt;td&gt;o,u&lt;/td&gt;  &lt;td&gt;घ&lt;/td&gt;  &lt;td&gt;gh&lt;/td&gt;  &lt;td&gt;थ&lt;/td&gt;  &lt;td&gt;th&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;क&lt;/td&gt;  &lt;td&gt;k,q,c&lt;/td&gt;  &lt;td&gt;व&lt;/td&gt;  &lt;td&gt;v,w&lt;/td&gt;  &lt;td&gt;ई&lt;/td&gt;  &lt;td&gt;e,i,y&lt;/td&gt;  &lt;td&gt;ध&lt;/td&gt;  &lt;td&gt;dh&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;p&gt;A straightforward python implementation for a function LevenshteinDistance that takes two strings, &lt;strong&gt;&lt;em&gt;src&lt;/em&gt;&lt;/strong&gt; of length m, and &lt;strong&gt;&lt;em&gt;trg&lt;/em&gt;&lt;/strong&gt; of length n, and a mapping table &lt;strong&gt;&lt;em&gt;map_table&lt;/em&gt;&lt;/strong&gt;, and returns the Levenshtein distance between the two strings is given below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;LevenshteinDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# source prefixes can be transformed into empty string by&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# dropping all characters&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# target prefixes can be reached from empty source prefix&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# by inserting every character&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;#// deletion&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;#// insertion&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;#// substitution&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Note that &lt;strong&gt;&lt;em&gt;map_table&lt;/em&gt;&lt;/strong&gt; is a python dictionary with Hindi letters as keys and their Roman mappings as values. The edit-distance returned is bounded between 0 to the length of largest string (source and target). These edit-distance scores are normalized between 0 to 1 simply by dividing the returned score with the length of the largest string. An edit-distance score of 1 between two strings with max-string length of 2 has a normalized edit-distance of 0.5, whereas the same score between two strings with max-string length of 10 has a normalized edit distance of 0.1. 
Translation pairs with a normalized score of less than a small threshold of &lt;strong&gt;~0.3&lt;/strong&gt; are considered as transliteration pairs. Note that the threshold is chosen by a rough observation of translation pairs and can vary for different language pairs.&lt;/p&gt;

&lt;h4 id=&quot;character-alignments-with-giza&quot;&gt;Character alignments with GIZA++&lt;/h4&gt;
&lt;p&gt;In order to train the transliteration system, we need to character align the transliteration pairs obtained above. We again use GIZA++ for this task. Let Hindi strings be the source and their Roman transliterations be the target for GIZA++ alignments. The resulting character alignments obtained using GIZA++ will look like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Sentence pair (1) source length 6 target length 10 alignment score : 3.91859e-13
m i s s i o n a r y
NULL ({ 5 6 8 }) म ({ 1 })  ि ({ 2 }) श ({ 3 4 }) न ({ 7 }) र ({ 9 }) ी ({ 10 })
# Sentence pair (2) source length 8 target length 6 alignment score : 1.5955e-05
u n i t e d
NULL ({ }) य ({ }) ू ({ 1 }) न ({ 2 }) ा ({ }) इ ({ 3 }) ट ({ 4 }) े ({ 5 }) ड ({ 6 })
# Sentence pair (3) source length 6 target length 8 alignment score : 9.23754e-05
a i sh w a r y a
NULL ({ 1 5 }) ऐ ({ 2 }) श ({ 3 }) व् ({ 4 }) र ({ 6 }) य ({ 7 }) ा ({ 8 })
# Sentence pair (4) source length 6 target length 8 alignment score : 0.0111937
n a r e n d r a
NULL ({ 2 8 }) न ({ 1 }) र ({ 3 }) े ({ 4 }) ं ({ 5 }) द ({ 6 }) र् ({ 7 })
.
.
.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Giza++ produces  four types of alignments: 1-to-1, 1-to-Many, 1-to-None and None-to-1. Out of these four letter alignments, None-to-1 alignments need to be handled. These alignments are modified by merging the target character with the previous aligned pair if it is not the first character, otherwise it is merged with the succeeding aligned character pair. The final training data for Hindi-to-Roman transliteration system will look like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;म   m
ि   i
श   ssio
न   na
र   r
ी   y

य   _
ू   u
न   n
ा   _
इ   i
ट   t
े   e
ड   d

ऐ   ai
श   sh
व्   wa
र   r
य   y
ा   a

न   na
र   r
े   e
ं   n
द   d
र्   ra

.
.
.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In order to create training data for Roman-to-Hindi system, we have to pass Roman strings as source and their Hindi transliterations as target to the character alignment process.&lt;/p&gt;

&lt;h3 id=&quot;training-the-transliteration-system&quot;&gt;Training the Transliteration System&lt;/h3&gt;

&lt;p&gt;Now that we have the training data, we can start the final training process. We can apply any ML algorithm to train the system. I model transliteration as a structure prediction problem with global feature representation. My transliteration model is basically a second order Hidden Markov Model (SHMM) formally represented in Equation below. I denote the sequence of letters in a word in source script as boldface &lt;strong&gt;s&lt;/strong&gt; and the sequence of hidden states which correspond to letter sequences in the target script as boldface &lt;strong&gt;t&lt;/strong&gt;. A basic HMM model has the following parameters:&lt;/p&gt;

&lt;center&gt;
&lt;pre lang=&quot;latex&quot;&gt;
P(\textbf{s};\textbf{t}) = \underset{t_{1}...t_{n}}{\arg\max}
{\overset{n}{\underset{i=1}{\prod}}}
\underbrace{P(t_{i}|t_{i-1},t_{i-2}) \rule[-5pt]{0pt}{1pt}}_{\mbox{\tiny Transition Probabilities}}
\underbrace{P(s_{i}|t_{i}) \rule[-5pt]{0pt}{1pt}}_{\mbox{\tiny Emission Probabilities}}
&lt;/pre&gt;
&lt;br /&gt;

&lt;div lang=&quot;latex&quot;&gt;
\text{where }{$s_{i}...s_{n}$} \text{ is a letter sequence in the source script, and } \\ {$t_{i}...t_{n}$} \text{ is the corresponding letter sequence in the target script.}
&lt;/div&gt;
&lt;/center&gt;

&lt;p&gt;I implemented &lt;a href=&quot;http://www.aclweb.org/anthology/W02-1001&quot;&gt;structured perceptron of Collins&lt;/a&gt; to learn the model parameters. Given an input training data of aligned character sequences &lt;span lang=&quot;latex&quot;&gt;D = d_1 \cdots d_n&lt;/span&gt;, a vector feature function &lt;span lang=&quot;latex&quot;&gt;\vec{f}(d)&lt;/span&gt;, and an initial weight vector &lt;span lang=&quot;latex&quot;&gt;\vec{w}&lt;/span&gt;, the algorithm performs two steps for each training example &lt;span lang=&quot;latex&quot;&gt;d_i\in D&lt;/span&gt;:&lt;/p&gt;

&lt;center&gt;
&lt;div lang=&quot;latex&quot;&gt;
\text{\textbf{Decode: }}\hat{t} = \underset{t_{1} \cdots t_{n}}{\arg\max} (\vec{w} \cdot \vec{f}(d))
&lt;/div&gt;

&lt;div lang=&quot;latex&quot;&gt;
\text{\textbf{Update: }}\vec{w} = \vec{w} + \vec{f}(d) - \vec{f}(\hat{t})
&lt;/div&gt;
&lt;/center&gt;

&lt;p&gt;With structured perceptron local contextual features can be made relevant to the whole sequence of target letters. It also allows us to use feature based emissions. I replace the basic multinomial emissions &lt;span lang=&quot;latex&quot;&gt;P(s_{i}|t_{i})&lt;/span&gt; with the feature-based emissions &lt;span lang=&quot;latex&quot;&gt;\vec{w} \cdot \vec{f}(d)&lt;/span&gt;. The feature template used to learn the emissions is shown in Table below. I use Viterbi-search to decode the best letter sequence in the target script while learning the parameters as well as at the time of testing.&lt;/p&gt;

&lt;p&gt;
&lt;center&gt;
&lt;table class=&quot;table-fill&quot;&gt;
&lt;tr&gt;
&lt;th&gt;&lt;b&gt;Ngram&lt;/b&gt;&lt;/th&gt; &lt;th&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Unigrams&lt;/td&gt;  &lt;td&gt;[l&lt;sub&gt;i-4&lt;/sub&gt;], [l&lt;sub&gt;i-3&lt;/sub&gt;], [l&lt;sub&gt;i-2&lt;/sub&gt;], [l&lt;sub&gt;i-1&lt;/sub&gt;], [l&lt;sub&gt;i&lt;/sub&gt;], [l&lt;sub&gt;i+1&lt;/sub&gt;], [l&lt;sub&gt;i+2&lt;/sub&gt;], [l&lt;sub&gt;i+3&lt;/sub&gt;], [l&lt;sub&gt;i+4&lt;/sub&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bigrams&lt;/td&gt;  &lt;td&gt;[l&lt;sub&gt;i-4&lt;/sub&gt; l&lt;sub&gt;i-3&lt;/sub&gt;], [l&lt;sub&gt;i-3&lt;/sub&gt; l&lt;sub&gt;i-2&lt;/sub&gt;], [l&lt;sub&gt;i-2&lt;/sub&gt; l&lt;sub&gt;i-1&lt;/sub&gt;], [l&lt;sub&gt;i-1&lt;/sub&gt; l&lt;sub&gt;i&lt;/sub&gt;], [l&lt;sub&gt;i&lt;/sub&gt; l&lt;sub&gt;i+1&lt;/sub&gt;], [l&lt;sub&gt;i+1&lt;/sub&gt; l&lt;sub&gt;i+2&lt;/sub&gt;], [l&lt;sub&gt;i+2&lt;/sub&gt; l&lt;sub&gt;i+3&lt;/sub&gt;], [l&lt;sub&gt;i+3&lt;/sub&gt; l&lt;sub&gt;i+4&lt;/sub&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Trigrams&lt;/td&gt;  &lt;td&gt;[l&lt;sub&gt;i-4&lt;/sub&gt; l&lt;sub&gt;i-3&lt;/sub&gt; l&lt;sub&gt;i-2&lt;/sub&gt;], [l&lt;sub&gt;i-3&lt;/sub&gt; l&lt;sub&gt;i-2&lt;/sub&gt; l&lt;sub&gt;i-1&lt;/sub&gt;], [l&lt;sub&gt;i-2&lt;/sub&gt; l&lt;sub&gt;i-1&lt;/sub&gt; l&lt;sub&gt;i&lt;/sub&gt;], [l&lt;sub&gt;i&lt;/sub&gt; l&lt;sub&gt;i+1&lt;/sub&gt; l&lt;sub&gt;i+2&lt;/sub&gt;], [l&lt;sub&gt;i+1&lt;/sub&gt; l&lt;sub&gt;i+2&lt;/sub&gt; l&lt;sub&gt;i+3&lt;/sub&gt;], [l&lt;sub&gt;i+2&lt;/sub&gt; l&lt;sub&gt;i+3&lt;/sub&gt; l&lt;sub&gt;i+4&lt;/sub&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tetragrams&lt;/td&gt;  &lt;td&gt;[l&lt;sub&gt;i-4&lt;/sub&gt; l&lt;sub&gt;i-3&lt;/sub&gt; l&lt;sub&gt;i-2&lt;/sub&gt; l&lt;sub&gt;i-1&lt;/sub&gt;], [l&lt;sub&gt;i-3&lt;/sub&gt; l&lt;sub&gt;i-2&lt;/sub&gt; l&lt;sub&gt;i-1&lt;/sub&gt; l&lt;sub&gt;i&lt;/sub&gt;], [l&lt;sub&gt;i-2&lt;/sub&gt; l&lt;sub&gt;i-1&lt;/sub&gt; l&lt;sub&gt;i&lt;/sub&gt; l&lt;sub&gt;i+1&lt;/sub&gt;], [l&lt;sub&gt;i-1&lt;/sub&gt; l&lt;sub&gt;i&lt;/sub&gt; l&lt;sub&gt;i+1&lt;/sub&gt; l&lt;sub&gt;i+2&lt;/sub&gt;], [l&lt;sub&gt;i&lt;/sub&gt; l&lt;sub&gt;i+1&lt;/sub&gt; l&lt;sub&gt;i+2&lt;/sub&gt; l&lt;sub&gt;i+3&lt;/sub&gt;], [l&lt;sub&gt;i+1&lt;/sub&gt; l&lt;sub&gt;i+2&lt;/sub&gt; l&lt;sub&gt;i+3&lt;/sub&gt; l&lt;sub&gt;i+4&lt;/sub&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;p&gt;Note that &lt;em&gt;l&lt;sub&gt;i-n&lt;/sub&gt;&lt;/em&gt; and &lt;em&gt;l&lt;sub&gt;i+n&lt;/sub&gt;&lt;/em&gt; represent the &lt;em&gt;nth&lt;/em&gt; preceding and succeeding letters of a given letter &lt;em&gt;l&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;till-mid-term-evaluation&quot;&gt;Till Mid-term Evaluation&lt;/h2&gt;

&lt;p&gt;My original proposal till midterm evaluation was to develop Indic-to-Roman and Roman-to-Indic transliteration systems for all scheduled Indian languages. The major challenge in the process was to extract and clean the training data for these systems. The extracted data for each model is split using &lt;em&gt;80-10-10&lt;/em&gt; rule where we use 80% of the data for training the model, 10% of the data for tuning the model parameters and rest 10% of the data for testing the system accuracy. Gladly I completed my work on time and the &lt;a href=&quot;https://github.com/irshadbhat/indic-trans&quot;&gt;final systems&lt;/a&gt; are ready to use. The work summary till midterm evaluation is given in the below table. Note that the training time is measured on an
&lt;strong&gt;Intel Core i5 1.2GHz CPU with 8GB RAM&lt;/strong&gt; and the training-time does not include data extraction or data loading time. Also note that Hindi, Nepali, Marathi, Konkani and Bodo all have Devanagari script and thus use Devanagari-Roman model and Bengali and Assamese both use Bengali models.
Devanagari-Roman represent both Devanagari-to-Roman and Roman-to-Devanagari systems and both systems take approximately equal training time. Similar goes for rest of the models.&lt;/p&gt;

&lt;p&gt;
&lt;center&gt;
&lt;table class=&quot;table-fill&quot;&gt;
&lt;col width=&quot;20&quot; /&gt;
&lt;col width=&quot;80&quot; /&gt;
&lt;col width=&quot;20&quot; /&gt;
&lt;tr&gt;
&lt;th&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/th&gt; &lt;th&gt;&lt;b&gt;Number of transliteration pairs extracted&lt;/b&gt;&lt;/th&gt;&lt;th&gt;&lt;b&gt;Training time (hours)&lt;/b&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Devanagari-Roman&lt;/td&gt; &lt;td&gt;87,520&lt;/td&gt; &lt;td&gt;(7-9)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bengali-Roman&lt;/td&gt; &lt;td&gt;44,939&lt;/td&gt; &lt;td&gt;(4-6)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gujarati-Roman&lt;/td&gt; &lt;td&gt;48,429&lt;/td&gt; &lt;td&gt;(4-6)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Punjabi-Roman&lt;/td&gt; &lt;td&gt;33,841&lt;/td&gt; &lt;td&gt;(4-5)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Malayalam-Roman&lt;/td&gt; &lt;td&gt;28,555&lt;/td&gt; &lt;td&gt;(3-5)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kannada-Roman&lt;/td&gt; &lt;td&gt;37,877&lt;/td&gt; &lt;td&gt;(4-5)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tamil-Roman&lt;/td&gt; &lt;td&gt;36,478&lt;/td&gt; &lt;td&gt;(4-5)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Telugu-Roman&lt;/td&gt; &lt;td&gt;34,717&lt;/td&gt; &lt;td&gt;(4-5)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Oriya-Roman&lt;/td&gt; &lt;td&gt;29,542&lt;/td&gt; &lt;td&gt;(3-5)*2&lt;/td&gt; 
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;h3 id=&quot;how-to-use&quot;&gt;How to use&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;indictrans&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transliterator&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transliterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;hin&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;eng&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;hin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;कांग्रेस पार्टी अध्यक्ष सोनिया गांधी, तमिलनाडु की मुख्यमंत्री जयललिता और रिज़र्व बैंक के गवर्नर रघुराम राजन के बीच एक समानता है.
ये सभी अलग-अलग कारणों से भारतीय जनता पार्टी के राज्यसभा सांसद सुब्रमण्यम स्वामी के निशाने पर हैं.
उनके जयललिता और सोनिया गांधी के पीछे पड़ने का कारण कथित भ्रष्टाचार है.&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;eng&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;congress&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;party&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adhyaksh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sonia&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gandhi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tamilnadu&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kii&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mukhyamantri&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jayalalita&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;our&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;baink&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ke&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;governor&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raghuram&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rajan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ke&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beech&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ek&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samanta&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hai&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ye&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sabi&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alag&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carnon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;se&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bharatiya&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;janata&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;party&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ke&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rajyasabha&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saansad&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subramanyam&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;swami&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ke&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nishane&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;par&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;unke&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jayalalita&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;our&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sonia&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gandhi&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ke&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;peeche&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padane&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ka&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kaaran&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kathith&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bhrashtachar&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hai&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;trn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transliterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;eng&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;hin&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hin_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hin_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;कांग्रेस&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;पार्टी&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;अध्यक्ष&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;सोनिया&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;गांधी&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;तमिलनाडु&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;की&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;मुख्यमांत्री&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;जयललिता&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;और&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;रिज़र्व&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;बैंक&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;के&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;गवर्नर&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;रघुराम&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;राजन&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;के&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;बीच&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;एक&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;समानता&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;है&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;ये&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;सभी&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;अलग&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;अलग&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;कार्नों&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;से&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;भारतीय&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;जनता&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;पार्टी&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;के&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;राज्यसभा&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;स्&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;सद&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;सुब्रमण्यम&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;स्वामी&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;के&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;निशाने&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;पर&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;हैं&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;उनके&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;जयललिता&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;और&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;सोनिया&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;गांधी&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;के&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;पीछे&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;पड़ने&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;का&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;कारण&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;कथित&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;भ्रष्टाचार&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;है&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</content>
        </entry>
    
        <entry>
            <title>Squence Labeling</title>
            <link href="http://hankquinlan.github.io/squence-labeling/"/>
            <updated>2016-05-30T00:00:00+05:30</updated>
            <id>http://hankquinlan.github.io//squence-labelling</id>
            <content type="html">&lt;p&gt;What is squence labeling? How is it different from simple classification and what are the underlying challenges?&lt;/p&gt;
</content>
        </entry>
    
        <entry>
            <title>Language Identification</title>
            <link href="http://hankquinlan.github.io/lang-id/"/>
            <updated>2016-05-30T00:00:00+05:30</updated>
            <id>http://hankquinlan.github.io//lang-id</id>
            <content type="html">&lt;p&gt;What is language identification?&lt;/p&gt;
</content>
        </entry>
    
        <entry>
            <title>Machine Learning for text processing</title>
            <link href="http://hankquinlan.github.io/ML-text/"/>
            <updated>2016-05-30T00:00:00+05:30</updated>
            <id>http://hankquinlan.github.io//ML-text</id>
            <content type="html">&lt;p&gt;How can machine learning be used for text processing and understanding?&lt;/p&gt;
</content>
        </entry>
    

</feed>
